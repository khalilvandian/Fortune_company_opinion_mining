{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Google Colab Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnJEhwaD3Y9z"
      },
      "outputs": [],
      "source": [
        "# Colab Config\n",
        "\n",
        "%%capture\n",
        "!pip install emoji\n",
        "!pip install langdetect\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install langid\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IgsN66xxkLJS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "b:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import emoji\n",
        "import re\n",
        "from langdetect import detect, detect_langs\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from tqdm import tqdm\n",
        "import langid\n",
        "from ast import pattern\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W-EbxPYLQAb",
        "outputId": "a9f6e496-1704-46d9-cb12-f10c2f97ea57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\BlackDEATH\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\BlackDEATH\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\BlackDEATH\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehMTT-Nqs-BW"
      },
      "outputs": [],
      "source": [
        "# Download latest version\n",
        "# path = kagglehub.dataset_download(\"jarredgaudineer/social-media-posts-fortune-1000-companies\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztKxEaZuaRs"
      },
      "outputs": [],
      "source": [
        "# Using the 'path' variable from your previous code\n",
        "# downloaded_files = os.listdir(path)\n",
        "\n",
        "# print(\"Downloaded files:\", downloaded_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnX2gM6TxJAk"
      },
      "outputs": [],
      "source": [
        "# temp_df = pd.read_json(os.path.join(path, downloaded_files[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fellRRxrxfoz"
      },
      "outputs": [],
      "source": [
        "# temp_df['tweets'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSv7o4JHvxo0"
      },
      "outputs": [],
      "source": [
        "# combine path with the file name\n",
        "# files_directory = path\n",
        "# path = os.path.join(files_directory, \"10Mar2025.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQI8P1Fj2OMh",
        "outputId": "e5679501-cba6-4ff9-a362-08a512c10cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jeannicolasduval/2024-fortune-1000-companies?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 301k/301k [00:00<00:00, 637kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: C:\\Users\\BlackDEATH\\.cache\\kagglehub\\datasets\\jeannicolasduval\\2024-fortune-1000-companies\\versions\\1\n",
            "fortune1000_2024.csv\n",
            "fortune1000_2024.parquet\n",
            "fortune1000_companies.parquet\n",
            "fortune1000_companyinfo.parquet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# The List of Fortune 1000 Companies\n",
        "# Download latest version\n",
        "fort_list_path = kagglehub.dataset_download(\"jeannicolasduval/2024-fortune-1000-companies\")\n",
        "\n",
        "print(\"Path to dataset files:\", fort_list_path)\n",
        "\n",
        "for file in os.listdir(fort_list_path):\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "dVsG4uPl25j5",
        "outputId": "5ce3b80b-2d19-4d69-87c6-cc500f70d570"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Profitable</th>\n",
              "      <th>Founder_is_CEO</th>\n",
              "      <th>FemaleCEO</th>\n",
              "      <th>Growth_in_Jobs</th>\n",
              "      <th>Change_in_Rank</th>\n",
              "      <th>...</th>\n",
              "      <th>Assets_M</th>\n",
              "      <th>CEO</th>\n",
              "      <th>Country</th>\n",
              "      <th>HeadquartersCity</th>\n",
              "      <th>HeadquartersState</th>\n",
              "      <th>Website</th>\n",
              "      <th>CompanyType</th>\n",
              "      <th>Footnote</th>\n",
              "      <th>MarketCap_Updated_M</th>\n",
              "      <th>Updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>252399.0</td>\n",
              "      <td>C. Douglas McMillon</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Bentonville</td>\n",
              "      <td>Arkansas</td>\n",
              "      <td>https://www.stock.walmart.com</td>\n",
              "      <td>Public</td>\n",
              "      <td>Figures are for fiscal year ended Jan. 31, 202...</td>\n",
              "      <td>559911.0</td>\n",
              "      <td>2024-08-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>527854.0</td>\n",
              "      <td>Andrew R. Jassy</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>Washington</td>\n",
              "      <td>https://www.amazon.com</td>\n",
              "      <td>Public</td>\n",
              "      <td>Market value as of July 15, 2024.</td>\n",
              "      <td>2005565.0</td>\n",
              "      <td>2024-08-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Apple</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Computers, Office Equipment</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>352583.0</td>\n",
              "      <td>Timothy D. Cook</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Cupertino</td>\n",
              "      <td>California</td>\n",
              "      <td>https://www.apple.com</td>\n",
              "      <td>Public</td>\n",
              "      <td>Figures are for fiscal year ended Sept. 30, 20...</td>\n",
              "      <td>3594309.0</td>\n",
              "      <td>2024-08-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>UnitedHealth Group</td>\n",
              "      <td>UNH</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Health Care: Insurance and Managed Care</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>273720.0</td>\n",
              "      <td>Andrew P. Witty</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Minnetonka</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>https://www.unitedhealthgroup.com</td>\n",
              "      <td>Public</td>\n",
              "      <td>Market value as of July 15, 2024.</td>\n",
              "      <td>474339.0</td>\n",
              "      <td>2024-08-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Berkshire Hathaway</td>\n",
              "      <td>BRKA</td>\n",
              "      <td>Financials</td>\n",
              "      <td>Insurance: Property and Casualty (Stock)</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1069978.0</td>\n",
              "      <td>Warren E. Buffett</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Omaha</td>\n",
              "      <td>Nebraska</td>\n",
              "      <td>https://www.berkshirehathaway.com</td>\n",
              "      <td>Public</td>\n",
              "      <td>Market value as of July 15, 2024.</td>\n",
              "      <td>937028.0</td>\n",
              "      <td>2024-08-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rank             Company Ticker       Sector  \\\n",
              "0     1             Walmart    WMT    Retailing   \n",
              "1     2              Amazon   AMZN    Retailing   \n",
              "2     3               Apple   AAPL   Technology   \n",
              "3     4  UnitedHealth Group    UNH  Health Care   \n",
              "4     5  Berkshire Hathaway   BRKA   Financials   \n",
              "\n",
              "                                   Industry Profitable Founder_is_CEO  \\\n",
              "0                     General Merchandisers        yes             no   \n",
              "1           Internet Services and Retailing        yes             no   \n",
              "2               Computers, Office Equipment        yes             no   \n",
              "3   Health Care: Insurance and Managed Care        yes             no   \n",
              "4  Insurance: Property and Casualty (Stock)        yes             no   \n",
              "\n",
              "  FemaleCEO Growth_in_Jobs  Change_in_Rank  ...   Assets_M  \\\n",
              "0        no             no             0.0  ...   252399.0   \n",
              "1        no             no             0.0  ...   527854.0   \n",
              "2        no             no             1.0  ...   352583.0   \n",
              "3        no            yes             1.0  ...   273720.0   \n",
              "4        no            yes             2.0  ...  1069978.0   \n",
              "\n",
              "                   CEO Country HeadquartersCity HeadquartersState  \\\n",
              "0  C. Douglas McMillon    U.S.      Bentonville          Arkansas   \n",
              "1      Andrew R. Jassy    U.S.          Seattle        Washington   \n",
              "2      Timothy D. Cook    U.S.        Cupertino        California   \n",
              "3      Andrew P. Witty    U.S.       Minnetonka         Minnesota   \n",
              "4    Warren E. Buffett    U.S.            Omaha          Nebraska   \n",
              "\n",
              "                             Website  CompanyType  \\\n",
              "0      https://www.stock.walmart.com       Public   \n",
              "1             https://www.amazon.com       Public   \n",
              "2              https://www.apple.com       Public   \n",
              "3  https://www.unitedhealthgroup.com       Public   \n",
              "4  https://www.berkshirehathaway.com       Public   \n",
              "\n",
              "                                            Footnote  MarketCap_Updated_M  \\\n",
              "0  Figures are for fiscal year ended Jan. 31, 202...             559911.0   \n",
              "1                  Market value as of July 15, 2024.            2005565.0   \n",
              "2  Figures are for fiscal year ended Sept. 30, 20...            3594309.0   \n",
              "3                  Market value as of July 15, 2024.             474339.0   \n",
              "4                  Market value as of July 15, 2024.             937028.0   \n",
              "\n",
              "      Updated  \n",
              "0  2024-08-05  \n",
              "1  2024-08-05  \n",
              "2  2024-08-05  \n",
              "3  2024-08-05  \n",
              "4  2024-08-05  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fortune_company_list = pd.read_csv(os.path.join(fort_list_path, \"fortune1000_2024.csv\"))\n",
        "fortune_company_list.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTAMUZ3L4ja-",
        "outputId": "a8cb5148-9adc-4169-f097-01753e38265a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L43ipoo-4fJg"
      },
      "outputs": [],
      "source": [
        "# Specify the file path within your Drive\n",
        "# path = '/content/drive/MyDrive/companyDataSample.json'\n",
        "path = '/content/drive/MyDrive/allCompanyData.json'\n",
        "\n",
        "# Save the data as a JSON file\n",
        "# with open(path, 'w') as f:\n",
        "#     json.dump(data, f)\n",
        "\n",
        "# print(f\"Data saved to: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MvJOjIJewDDE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "path = '../Data/allCompanyData.json'\n",
        "with open(path, 'r') as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj9pCl9RxPkk",
        "outputId": "aa80183a-0710-4c8f-c88e-ec7fe2d8dbdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['company', 'rank', 'timestamp', 'tweets', 'posts', 'comments', 'metadata'])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KP1-uO64lRJ3",
        "outputId": "2558ccb0-57ac-4af1-d500-75fd919aa38a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>$GOOGL $GOOG $WMT Google And Walmart Payment A...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>Can $PHNIX become the first meme coin to dethr...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>Walmart $WMT \\n\\nThe Laughing Cow Cheese, 32 p...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>Some of the most iconic businesses ever \\n\\n1....</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>Walmart $WMT currently has 1.05 Billion Square...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591342</th>\n",
              "      <td>Clear Channel Outdoor Hldgs.</td>\n",
              "      <td>Hi BUB Sub!\\n\\n\\nHad this account on the back ...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591343</th>\n",
              "      <td>Clear Channel Outdoor Hldgs.</td>\n",
              "      <td>I am curious how these events typically play o...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591344</th>\n",
              "      <td>Clear Channel Outdoor Hldgs.</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591345</th>\n",
              "      <td>Clear Channel Outdoor Hldgs.</td>\n",
              "      <td>The Role of the National Weather Service in Em...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591346</th>\n",
              "      <td>Clear Channel Outdoor Hldgs.</td>\n",
              "      <td>How to Get Money from Side Hustles: Strategies...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>591347 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Company  \\\n",
              "0                            Walmart   \n",
              "1                            Walmart   \n",
              "2                            Walmart   \n",
              "3                            Walmart   \n",
              "4                            Walmart   \n",
              "...                              ...   \n",
              "591342  Clear Channel Outdoor Hldgs.   \n",
              "591343  Clear Channel Outdoor Hldgs.   \n",
              "591344  Clear Channel Outdoor Hldgs.   \n",
              "591345  Clear Channel Outdoor Hldgs.   \n",
              "591346  Clear Channel Outdoor Hldgs.   \n",
              "\n",
              "                                                     Text        Source  \n",
              "0       $GOOGL $GOOG $WMT Google And Walmart Payment A...       Twitter  \n",
              "1       Can $PHNIX become the first meme coin to dethr...       Twitter  \n",
              "2       Walmart $WMT \\n\\nThe Laughing Cow Cheese, 32 p...       Twitter  \n",
              "3       Some of the most iconic businesses ever \\n\\n1....       Twitter  \n",
              "4       Walmart $WMT currently has 1.05 Billion Square...       Twitter  \n",
              "...                                                   ...           ...  \n",
              "591342  Hi BUB Sub!\\n\\n\\nHad this account on the back ...  Reddit-Posts  \n",
              "591343  I am curious how these events typically play o...  Reddit-Posts  \n",
              "591344                                                     Reddit-Posts  \n",
              "591345  The Role of the National Weather Service in Em...  Reddit-Posts  \n",
              "591346  How to Get Money from Side Hustles: Strategies...  Reddit-Posts  \n",
              "\n",
              "[591347 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = [\"Company\", \"Text\", \"Source\"]\n",
        "atts_temp = [\"tweets\", \"comments\", \"posts\"]\n",
        "source_dic = {\"tweets\": \"Twitter\", \"comments\": \"Reddit-Comments\", \"posts\": \"Reddit-Posts\"}\n",
        "mp_doc_list = []\n",
        "\n",
        "for company in data:\n",
        "  for text_list in atts_temp:\n",
        "    if text_list in company:\n",
        "      for text in company[text_list]:\n",
        "        mp_doc_list.append([company[\"company\"], text[\"text\"], source_dic[text_list]])\n",
        "\n",
        "\n",
        "data_df = pd.DataFrame(mp_doc_list, columns=columns)\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "B_Ec47LW4dZ7",
        "outputId": "ccbd2238-2fa6-4f0d-eae2-586b8b46bd16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500506</th>\n",
              "      <td>DexCom</td>\n",
              "      <td>DXCM</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Medical Products and Equipment</td>\n",
              "      <td>I NEED my over-patch, but I can’t use the Dexc...</td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126815</th>\n",
              "      <td>HP</td>\n",
              "      <td>HPQ</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Computers, Office Equipment</td>\n",
              "      <td>You've covered pretty much everything. \\n\\nI w...</td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579836</th>\n",
              "      <td>Spire</td>\n",
              "      <td>SR</td>\n",
              "      <td>Energy</td>\n",
              "      <td>Utilities: Gas and Electric</td>\n",
              "      <td>I know it has been talked about and rumored fo...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572664</th>\n",
              "      <td>Etsy</td>\n",
              "      <td>ETSY</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td>hi! i know some people have mentioned that ets...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184996</th>\n",
              "      <td>PNC Financial Services Group</td>\n",
              "      <td>PNC</td>\n",
              "      <td>Financials</td>\n",
              "      <td>Commercial Banks</td>\n",
              "      <td>* **UnitedHealth Group (**[UNH](https://stockn...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327257</th>\n",
              "      <td>NVR</td>\n",
              "      <td>NVR</td>\n",
              "      <td>Engineering &amp; Construction</td>\n",
              "      <td>Homebuilders</td>\n",
              "      <td>Hi All\\n\\nI want to get 2x 8MP and 2x 4MP came...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300476</th>\n",
              "      <td>Williams</td>\n",
              "      <td>WMB</td>\n",
              "      <td>Energy</td>\n",
              "      <td>Pipelines</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356548</th>\n",
              "      <td>XPO</td>\n",
              "      <td>XPO</td>\n",
              "      <td>Transportation</td>\n",
              "      <td>Transportation and Logistics</td>\n",
              "      <td>Hi everyone,\\n\\nI recently upgraded my CPU fro...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150991</th>\n",
              "      <td>Warner Bros. Discovery</td>\n",
              "      <td>WBD</td>\n",
              "      <td>Media</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305392</th>\n",
              "      <td>Hess</td>\n",
              "      <td>HES</td>\n",
              "      <td>Energy</td>\n",
              "      <td>Mining, Crude-Oil Production</td>\n",
              "      <td>[Book 1 on Amazon!](https://www.amazon.com/Die...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Company Ticker                      Sector  \\\n",
              "500506                        DexCom   DXCM                 Health Care   \n",
              "126815                            HP    HPQ                  Technology   \n",
              "579836                         Spire     SR                      Energy   \n",
              "572664                          Etsy   ETSY                   Retailing   \n",
              "184996  PNC Financial Services Group    PNC                  Financials   \n",
              "327257                           NVR    NVR  Engineering & Construction   \n",
              "300476                      Williams    WMB                      Energy   \n",
              "356548                           XPO    XPO              Transportation   \n",
              "150991        Warner Bros. Discovery    WBD                       Media   \n",
              "305392                          Hess    HES                      Energy   \n",
              "\n",
              "                               Industry  \\\n",
              "500506   Medical Products and Equipment   \n",
              "126815      Computers, Office Equipment   \n",
              "579836      Utilities: Gas and Electric   \n",
              "572664  Internet Services and Retailing   \n",
              "184996                 Commercial Banks   \n",
              "327257                     Homebuilders   \n",
              "300476                        Pipelines   \n",
              "356548     Transportation and Logistics   \n",
              "150991                    Entertainment   \n",
              "305392     Mining, Crude-Oil Production   \n",
              "\n",
              "                                                     Text           Source  \n",
              "500506  I NEED my over-patch, but I can’t use the Dexc...  Reddit-Comments  \n",
              "126815  You've covered pretty much everything. \\n\\nI w...  Reddit-Comments  \n",
              "579836  I know it has been talked about and rumored fo...     Reddit-Posts  \n",
              "572664  hi! i know some people have mentioned that ets...     Reddit-Posts  \n",
              "184996  * **UnitedHealth Group (**[UNH](https://stockn...     Reddit-Posts  \n",
              "327257  Hi All\\n\\nI want to get 2x 8MP and 2x 4MP came...     Reddit-Posts  \n",
              "300476                                                        Reddit-Posts  \n",
              "356548  Hi everyone,\\n\\nI recently upgraded my CPU fro...     Reddit-Posts  \n",
              "150991                                                        Reddit-Posts  \n",
              "305392  [Book 1 on Amazon!](https://www.amazon.com/Die...     Reddit-Posts  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enriched_data = pd.merge(fortune_company_list[[\"Company\", \"Ticker\", \"Sector\", \"Industry\"]], data_df, left_on=\"Company\", right_on=\"Company\")\n",
        "enriched_data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK9TF7LHSzEd",
        "outputId": "3630804b-efbd-4465-ed9d-4e42444dccf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of companies in the enriched dataset: 953\n",
            "Number of companies in the main dataset: 953\n"
          ]
        }
      ],
      "source": [
        "# compare unique companies in the enriched dataset and main dataset\n",
        "enriched_companies = enriched_data[\"Company\"].unique()\n",
        "main_companies = data_df[\"Company\"].unique()\n",
        "\n",
        "print(f\"Number of companies in the enriched dataset: {len(enriched_companies)}\")\n",
        "print(f\"Number of companies in the main dataset: {len(main_companies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y_S8g8urTgda"
      },
      "outputs": [],
      "source": [
        "data_df = enriched_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w0_MtbjQFj9"
      },
      "source": [
        "## Preprocessing the texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Igy_s7FR7h3C",
        "outputId": "b6eab888-176b-4415-8b7a-ed27a7ef11d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>591347</td>\n",
              "      <td>579881</td>\n",
              "      <td>591347</td>\n",
              "      <td>591347</td>\n",
              "      <td>591347</td>\n",
              "      <td>591347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>953</td>\n",
              "      <td>932</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>487445</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Tesla</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>9438</td>\n",
              "      <td>9438</td>\n",
              "      <td>132908</td>\n",
              "      <td>60577</td>\n",
              "      <td>82315</td>\n",
              "      <td>329493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Company  Ticker      Sector                         Industry    Text  \\\n",
              "count   591347  579881      591347                           591347  591347   \n",
              "unique     953     932          21                               75  487445   \n",
              "top      Tesla    TSLA  Technology  Internet Services and Retailing           \n",
              "freq      9438    9438      132908                            60577   82315   \n",
              "\n",
              "              Source  \n",
              "count         591347  \n",
              "unique             3  \n",
              "top     Reddit-Posts  \n",
              "freq          329493  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "OUmGEK6N762a",
        "outputId": "e7eb2361-ffca-4ce9-cc0a-1bcbc9ca5791"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>256909</th>\n",
              "      <td>Gap</td>\n",
              "      <td>GPS</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>Specialty Retailers: Apparel</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212018</th>\n",
              "      <td>Block</td>\n",
              "      <td>SQ</td>\n",
              "      <td>Business Services</td>\n",
              "      <td>Financial Data Services</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251849</th>\n",
              "      <td>Fox</td>\n",
              "      <td>FOXA</td>\n",
              "      <td>Media</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344596</th>\n",
              "      <td>PPL</td>\n",
              "      <td>PPL</td>\n",
              "      <td>Energy</td>\n",
              "      <td>Utilities: Gas and Electric</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388828</th>\n",
              "      <td>PENN Entertainment</td>\n",
              "      <td>PENN</td>\n",
              "      <td>Hotels, Restaurants &amp; Leisure</td>\n",
              "      <td>Hotels, Casinos, Resorts</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388573</th>\n",
              "      <td>PENN Entertainment</td>\n",
              "      <td>PENN</td>\n",
              "      <td>Hotels, Restaurants &amp; Leisure</td>\n",
              "      <td>Hotels, Casinos, Resorts</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72146</th>\n",
              "      <td>Tesla</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>Motor Vehicles &amp; Parts</td>\n",
              "      <td>Motor Vehicles &amp; Parts</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507450</th>\n",
              "      <td>Roku</td>\n",
              "      <td>ROKU</td>\n",
              "      <td>Media</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>See it for free over-the-air on your local ABC...</td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374264</th>\n",
              "      <td>Agilent Technologies</td>\n",
              "      <td>A</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Scientific,Photographic and  Control Equipment</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60717</th>\n",
              "      <td>Target</td>\n",
              "      <td>TGT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>\\n(Always Looking)\\n\\nI can play female or fem...</td>\n",
              "      <td>Reddit-Posts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Company Ticker                         Sector  \\\n",
              "256909                   Gap    GPS                      Retailing   \n",
              "212018                 Block     SQ              Business Services   \n",
              "251849                   Fox   FOXA                          Media   \n",
              "344596                   PPL    PPL                         Energy   \n",
              "388828    PENN Entertainment   PENN  Hotels, Restaurants & Leisure   \n",
              "388573    PENN Entertainment   PENN  Hotels, Restaurants & Leisure   \n",
              "72146                  Tesla   TSLA         Motor Vehicles & Parts   \n",
              "507450                  Roku   ROKU                          Media   \n",
              "374264  Agilent Technologies      A                     Technology   \n",
              "60717                 Target    TGT                      Retailing   \n",
              "\n",
              "                                              Industry  \\\n",
              "256909                    Specialty Retailers: Apparel   \n",
              "212018                         Financial Data Services   \n",
              "251849                                   Entertainment   \n",
              "344596                     Utilities: Gas and Electric   \n",
              "388828                        Hotels, Casinos, Resorts   \n",
              "388573                        Hotels, Casinos, Resorts   \n",
              "72146                           Motor Vehicles & Parts   \n",
              "507450                                   Entertainment   \n",
              "374264  Scientific,Photographic and  Control Equipment   \n",
              "60717                            General Merchandisers   \n",
              "\n",
              "                                                     Text           Source  \n",
              "256909                                                        Reddit-Posts  \n",
              "212018                                                        Reddit-Posts  \n",
              "251849                                                        Reddit-Posts  \n",
              "344596                                                        Reddit-Posts  \n",
              "388828                                                        Reddit-Posts  \n",
              "388573                                                        Reddit-Posts  \n",
              "72146                                                         Reddit-Posts  \n",
              "507450  See it for free over-the-air on your local ABC...  Reddit-Comments  \n",
              "374264                                                        Reddit-Posts  \n",
              "60717   \\n(Always Looking)\\n\\nI can play female or fem...     Reddit-Posts  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show duplicates\n",
        "data_df[data_df.duplicated()].sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "qpAim3XH8RHD",
        "outputId": "4772156f-1187-4e5a-8138-c0ceed6d45c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>490487</td>\n",
              "      <td>480398</td>\n",
              "      <td>490487</td>\n",
              "      <td>490487</td>\n",
              "      <td>490487</td>\n",
              "      <td>490487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>953</td>\n",
              "      <td>932</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>487445</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Tesla</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td></td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>7372</td>\n",
              "      <td>7372</td>\n",
              "      <td>110765</td>\n",
              "      <td>49625</td>\n",
              "      <td>883</td>\n",
              "      <td>242717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Company  Ticker      Sector                         Industry    Text  \\\n",
              "count   490487  480398      490487                           490487  490487   \n",
              "unique     953     932          21                               75  487445   \n",
              "top      Tesla    TSLA  Technology  Internet Services and Retailing           \n",
              "freq      7372    7372      110765                            49625     883   \n",
              "\n",
              "                 Source  \n",
              "count            490487  \n",
              "unique                3  \n",
              "top     Reddit-Comments  \n",
              "freq             242717  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop duplicates\n",
        "data_df = data_df.drop_duplicates()\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkjRb1ksu_14"
      },
      "source": [
        "### Sample for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "eJm5FRj98gRx",
        "outputId": "16993f6b-7678-4929-c974-3cd82ef63b07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>$GOOGL $GOOG $WMT Google And Walmart Payment A...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>Can $PHNIX become the first meme coin to dethr...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>Walmart $WMT \\n\\nThe Laughing Cow Cheese, 32 p...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>Some of the most iconic businesses ever \\n\\n1....</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Walmart</td>\n",
              "      <td>WMT</td>\n",
              "      <td>Retailing</td>\n",
              "      <td>General Merchandisers</td>\n",
              "      <td>Walmart $WMT currently has 1.05 Billion Square...</td>\n",
              "      <td>Twitter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Company Ticker     Sector               Industry  \\\n",
              "0  Walmart    WMT  Retailing  General Merchandisers   \n",
              "1  Walmart    WMT  Retailing  General Merchandisers   \n",
              "2  Walmart    WMT  Retailing  General Merchandisers   \n",
              "3  Walmart    WMT  Retailing  General Merchandisers   \n",
              "4  Walmart    WMT  Retailing  General Merchandisers   \n",
              "\n",
              "                                                Text   Source  \n",
              "0  $GOOGL $GOOG $WMT Google And Walmart Payment A...  Twitter  \n",
              "1  Can $PHNIX become the first meme coin to dethr...  Twitter  \n",
              "2  Walmart $WMT \\n\\nThe Laughing Cow Cheese, 32 p...  Twitter  \n",
              "3  Some of the most iconic businesses ever \\n\\n1....  Twitter  \n",
              "4  Walmart $WMT currently has 1.05 Billion Square...  Twitter  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_data_df = data_df.copy()\n",
        "sample_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y2oZ9fkJ5Q7D"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text, index, targets):\n",
        "\n",
        "  # First Demojize Text\n",
        "  edited_text = emoji.replace_emoji(text, '')\n",
        "\n",
        "  # Mask company\n",
        "  try:\n",
        "    pattern = r'(?<![a-zA-Z])(?:' + '|'.join(re.escape(word) for word in targets if isinstance(word, str)) + r')(?![a-zA-Z])'\n",
        "    if re.search(pattern, text, flags=re.IGNORECASE):\n",
        "        edited_text = re.sub(pattern, \"TargetedCompany\", text, flags=re.IGNORECASE)\n",
        "    else:\n",
        "        edited_text = \"\"\n",
        "\n",
        "  except Exception as e:\n",
        "    raise\n",
        "\n",
        "  # lower case\n",
        "  edited_text = edited_text.lower()\n",
        "\n",
        "  # remove links, mentions, hashtags\n",
        "  edited_text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", '', edited_text)\n",
        "\n",
        "  # Remove numbers\n",
        "  edited_text = re.sub(r'\\d+', '', edited_text)\n",
        "\n",
        "  # Remove non ASCII\n",
        "  edited_text = re.sub(r'[^\\x00-\\x7F]+', '', edited_text)\n",
        "\n",
        "  # remove extra spaces\n",
        "  edited_text = re.sub(r'\\s+', ' ', edited_text).strip()\n",
        "\n",
        "  # return if text is empty\n",
        "  if edited_text == \"\":\n",
        "    return edited_text\n",
        "\n",
        "  # Remove non english\n",
        "  try:\n",
        "    # lang = detect(edited_text)\n",
        "    lang, _ = langid.classify(edited_text)\n",
        "    if lang != \"en\":\n",
        "        edited_text = \"\"\n",
        "  except Exception as e:\n",
        "    # print(f\"Error detecting language for text at index {index} and content:{edited_text}: {e}\")\n",
        "    edited_text = \"\"\n",
        "\n",
        "  return edited_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "NUv8ClBW3rHj",
        "outputId": "7c715145-5ae0-4028-aed6-e412a4bc261d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 6537/490487 [00:39<48:41, 165.66it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m temp_df = sample_data_df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m temp_df[\u001b[33m\"\u001b[39m\u001b[33mText\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtemp_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCompany\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTicker\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m temp_df\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\tqdm\\std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\tqdm\\std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m      1\u001b[39m temp_df = sample_data_df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m temp_df[\u001b[33m\"\u001b[39m\u001b[33mText\u001b[39m\u001b[33m\"\u001b[39m] = temp_df.progress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCompany\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTicker\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m temp_df\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text, index, targets)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Remove non english\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     38\u001b[39m   \u001b[38;5;66;03m# lang = detect(edited_text)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m   lang, _ = \u001b[43mlangid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43medited_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m lang != \u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     41\u001b[39m       edited_text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\langid\\langid.py:107\u001b[39m, in \u001b[36mclassify\u001b[39m\u001b[34m(instance)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m   load_model()\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43midentifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\langid\\langid.py:295\u001b[39m, in \u001b[36mLanguageIdentifier.classify\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03mClassify an instance.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m fv = \u001b[38;5;28mself\u001b[39m.instance2fv(text)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m probs = \u001b[38;5;28mself\u001b[39m.norm_probs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnb_classprobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    296\u001b[39m cl = np.argmax(probs)\n\u001b[32m    297\u001b[39m conf = \u001b[38;5;28mfloat\u001b[39m(probs[cl])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mb:\\Projects\\BehavioralPsychology\\Fortune_company_opinion_mining\\venv\\Lib\\site-packages\\langid\\langid.py:285\u001b[39m, in \u001b[36mLanguageIdentifier.nb_classprobs\u001b[39m\u001b[34m(self, fv)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnb_classprobs\u001b[39m(\u001b[38;5;28mself\u001b[39m, fv):\n\u001b[32m    284\u001b[39m   \u001b[38;5;66;03m# compute the partial log-probability of the document given each class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m   pdc = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnb_ptc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m   \u001b[38;5;66;03m# compute the partial log-probability of the document in each class\u001b[39;00m\n\u001b[32m    287\u001b[39m   pd = pdc + \u001b[38;5;28mself\u001b[39m.nb_pc\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "temp_df = sample_data_df.copy()\n",
        "temp_df[\"Text\"] = temp_df.progress_apply(lambda row: preprocess_text(row[\"Text\"], row.name, [row[\"Company\"], row[\"Ticker\"]]), axis=1)\n",
        "temp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-kR6l52JD86"
      },
      "source": [
        "### Remove All blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "iPCB4S-1JDMm",
        "outputId": "568d0dc9-3ac2-4e39-b296-08c44ed71676"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"temp_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          919,\n          \"6841\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          898,\n          \"6841\",\n          \"336538\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          21,\n          \"87823\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Industry\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          75,\n          \"40699\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          339469,\n          \"278\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"174806\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a64c8809-f4ab-4b7f-9857-88d32bfe00bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>345786</td>\n",
              "      <td>336538</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>919</td>\n",
              "      <td>898</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>339469</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Tesla</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td>[</td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>6841</td>\n",
              "      <td>6841</td>\n",
              "      <td>87823</td>\n",
              "      <td>40699</td>\n",
              "      <td>278</td>\n",
              "      <td>174806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a64c8809-f4ab-4b7f-9857-88d32bfe00bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a64c8809-f4ab-4b7f-9857-88d32bfe00bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a64c8809-f4ab-4b7f-9857-88d32bfe00bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aa507648-d4ce-4e00-9268-be9f2f23b600\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa507648-d4ce-4e00-9268-be9f2f23b600')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aa507648-d4ce-4e00-9268-be9f2f23b600 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Company  Ticker      Sector                         Industry    Text  \\\n",
              "count   345786  336538      345786                           345786  345786   \n",
              "unique     919     898          21                               75  339469   \n",
              "top      Tesla    TSLA  Technology  Internet Services and Retailing       [   \n",
              "freq      6841    6841       87823                            40699     278   \n",
              "\n",
              "                 Source  \n",
              "count            345786  \n",
              "unique                3  \n",
              "top     Reddit-Comments  \n",
              "freq             174806  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df = temp_df[temp_df[\"Text\"] != \"\"]\n",
        "temp_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAesNGxKekE-"
      },
      "source": [
        "### Wrap up pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Xae4ynm1I4pa",
        "outputId": "d76121aa-c6c3-42a8-b501-e4ddc0212e9c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"temp_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          919,\n          \"6841\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          898,\n          \"6841\",\n          \"336538\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          21,\n          \"87823\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Industry\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          75,\n          \"40699\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          339469,\n          \"278\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"174806\",\n          \"345786\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-77fc6482-d4a4-4fae-a0da-22939ecb235d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "      <th>Text</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>345786</td>\n",
              "      <td>336538</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "      <td>345786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>919</td>\n",
              "      <td>898</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>339469</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Tesla</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Internet Services and Retailing</td>\n",
              "      <td>[</td>\n",
              "      <td>Reddit-Comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>6841</td>\n",
              "      <td>6841</td>\n",
              "      <td>87823</td>\n",
              "      <td>40699</td>\n",
              "      <td>278</td>\n",
              "      <td>174806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77fc6482-d4a4-4fae-a0da-22939ecb235d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77fc6482-d4a4-4fae-a0da-22939ecb235d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77fc6482-d4a4-4fae-a0da-22939ecb235d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-185e9bb1-819d-433d-bd62-de824a57a95e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-185e9bb1-819d-433d-bd62-de824a57a95e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-185e9bb1-819d-433d-bd62-de824a57a95e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Company  Ticker      Sector                         Industry    Text  \\\n",
              "count   345786  336538      345786                           345786  345786   \n",
              "unique     919     898          21                               75  339469   \n",
              "top      Tesla    TSLA  Technology  Internet Services and Retailing       [   \n",
              "freq      6841    6841       87823                            40699     278   \n",
              "\n",
              "                 Source  \n",
              "count            345786  \n",
              "unique                3  \n",
              "top     Reddit-Comments  \n",
              "freq             174806  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SqpZDQJ9-8M"
      },
      "source": [
        "Saving the preprocesed data into the drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBGgP2x49PXW"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/preprocessedCompanyData.json'\n",
        "\n",
        "# # Save the data as a JSON file\n",
        "# with open(path, 'w') as f:\n",
        "#     json.dump(data, f)\n",
        "\n",
        "# read the saved preprocessed data\n",
        "with open(path, 'r') as f:\n",
        "    preprocessed_text_data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69WvTCkG2tjp"
      },
      "source": [
        "## Vectorization and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHoKjWKILgi7"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "target_filter = \"targetedcompany\"\n",
        "\n",
        "def tokenize_text(text):\n",
        "\n",
        "  # first remove punct\n",
        "  no_punct = [char for char in text if char not in string.punctuation]\n",
        "  no_punct = \"\".join(no_punct)\n",
        "\n",
        "  # replace ’ with '\n",
        "  no_punct = no_punct.replace(\"’\", \"'\")\n",
        "\n",
        "  # Lemmatize\n",
        "  doc = no_punct.split()\n",
        "\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    lemmed = lemmatizer.lemmatize(token)\n",
        "    if lemmed not in stop_words and lemmed != target_filter:\n",
        "      tokens.append(lemmed)\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU51RRWq87Pp"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = temp_df.sample(10, random_state=28).apply(lambda row: tokenize_text(row[\"Text\"]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "16rDUK_ywJpB",
        "outputId": "ab4193e0-6f54-4e18-f3e4-ebf5766afad7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446134</th>\n",
              "      <td>[possible, disable, building, time, useful, so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335304</th>\n",
              "      <td>[youre, fence, ordering, tesla, targetedcompan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209031</th>\n",
              "      <td>[hi, name, disclosure, ive, researching, issue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81658</th>\n",
              "      <td>[mufasa, lion, king, picture, week, weekend, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470657</th>\n",
              "      <td>[five, week, oh, ross, procedure, thing, mostl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404454</th>\n",
              "      <td>[pen, la, time, crossword, clue, guide, la, ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213944</th>\n",
              "      <td>[brother, ill, happy, support, match, except, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396252</th>\n",
              "      <td>[want, use, port, pair, gpu, using, link, fsg,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342478</th>\n",
              "      <td>[drove, gamespot, opened, like, wa, online, dr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144735</th>\n",
              "      <td>[join, discord, pay, sub, get, monitor, notifi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "446134    [possible, disable, building, time, useful, so...\n",
              "335304    [youre, fence, ordering, tesla, targetedcompan...\n",
              "209031    [hi, name, disclosure, ive, researching, issue...\n",
              "81658     [mufasa, lion, king, picture, week, weekend, r...\n",
              "470657    [five, week, oh, ross, procedure, thing, mostl...\n",
              "404454    [pen, la, time, crossword, clue, guide, la, ti...\n",
              "213944    [brother, ill, happy, support, match, except, ...\n",
              "396252    [want, use, port, pair, gpu, using, link, fsg,...\n",
              "342478    [drove, gamespot, opened, like, wa, online, dr...\n",
              "144735    [join, discord, pay, sub, get, monitor, notifi...\n",
              "dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "uv39qBk8ImT3",
        "outputId": "b2b01ab8-472f-4335-fadf-421712d3635e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-64e6ee6f22ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.995\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-b3dfe4e448f2>\u001b[0m in \u001b[0;36mtokenize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mlemmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlemmed\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlemmed\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mshortest\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m     32\u001b[0m         \u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mWordNet\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0m_morphy\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "vectorizer = CountVectorizer(analyzer=tokenize_text, min_df=0.005, max_df=0.995)\n",
        "bow = vectorizer.fit_transform(temp_df[\"Text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdRVktzBLI-s"
      },
      "outputs": [],
      "source": [
        "len(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0O1HtTyZlrF"
      },
      "outputs": [],
      "source": [
        "print(f\"Shape of the BOW: {bow.shape}\")\n",
        "print(f\"Number of non-zero values: {bow.nnz}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1okzr2OJYhLU"
      },
      "outputs": [],
      "source": [
        "tf_idf = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQE6cs0Kprvc"
      },
      "outputs": [],
      "source": [
        "tf_idf_text = tf_idf.fit_transform(bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urgQOFITsOOr"
      },
      "outputs": [],
      "source": [
        "tf_idf_text.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmQA0psFS6eH"
      },
      "source": [
        "## Topic Modeling The texts\n",
        "Initially, we need to understand what sort of content we have. This will help deciding if we should go with data based topics or anchored topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJZA9haaiDMJ"
      },
      "outputs": [],
      "source": [
        "lda = LatentDirichletAllocation(n_components=6, max_iter=10, learning_method='batch', random_state=42, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkC4gxnmj-8q"
      },
      "outputs": [],
      "source": [
        "lda_op = lda.fit_transform(tf_idf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuZPYP9WkVys"
      },
      "outputs": [],
      "source": [
        "lda_op.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7yU4z7hk0xa"
      },
      "outputs": [],
      "source": [
        "lda_op[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIIdeV2zmda8"
      },
      "outputs": [],
      "source": [
        "H1 = lda.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWGLomgtminA"
      },
      "outputs": [],
      "source": [
        "num_words = 20\n",
        "vocab = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
        "topic_words = ([top_words(t) for t in H1])\n",
        "topics = [' '.join(t) for t in topic_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYYh4x5hpH4K"
      },
      "outputs": [],
      "source": [
        "topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSMDCsZmDQhk"
      },
      "outputs": [],
      "source": [
        "lda_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3Dd5TAzzE30"
      },
      "outputs": [],
      "source": [
        "temp_df[\"Topic\"] = np.argmax(lda_op, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3FWF7haz8Nr"
      },
      "outputs": [],
      "source": [
        "temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjDYUAjJX_9B"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/allCompanyData_TopicModeled.csv'\n",
        "# temp_df.to_csv(path)\n",
        "# print(f\"Data saved to: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74dqTrnpYyKx"
      },
      "outputs": [],
      "source": [
        "# Map topic index to a descriptive title\n",
        "topic_titles = {\n",
        "    0: \"Casual Online Chatter\",\n",
        "    1: \"Book or Media Reviews\",\n",
        "    2: \"Consumer Goods / Retail\",\n",
        "    3: \"Finance & Business News\",\n",
        "    4: \"Job Applications & Recruitment\",\n",
        "    5: \"Tech Support & Software Use\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s48S3ZPcY_ag"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count topics\n",
        "topic_counts = temp_df[\"Topic\"].value_counts().sort_index()\n",
        "\n",
        "# Map the index to topic titles for labeling\n",
        "labels = [topic_titles[i] for i in topic_counts.index]\n",
        "\n",
        "# Plot with titles as x-axis labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels, topic_counts.values)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Document Counts per Topic\")\n",
        "plt.ylabel(\"Number of Documents\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L1mspvgdwqQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Group data by sector and topic, and count occurrences\n",
        "sector_topic_counts = temp_df.groupby(['Sector', 'Topic'])['Topic'].count().unstack()\n",
        "\n",
        "# Get sector and topic labels\n",
        "sectors = sector_topic_counts.index\n",
        "topic_labels = [topic_titles[i] for i in range(lda.n_components)]\n",
        "\n",
        "# Create the stacked bar chart\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot bars for each topic within each sector\n",
        "bottom = [0] * len(sectors)  # Initialize bottom for stacking\n",
        "for i, topic_label in enumerate(topic_labels):\n",
        "    ax.bar(sectors, sector_topic_counts[i], label=topic_label, bottom=bottom)\n",
        "    bottom = [bottom[j] + sector_topic_counts[i][j] for j in range(len(sectors))]\n",
        "\n",
        "# Set chart labels and formatting\n",
        "ax.set_xlabel(\"Sector\")\n",
        "ax.set_ylabel(\"Number of Documents\")\n",
        "ax.set_title(\"Topic Distribution Across Sectors\")\n",
        "ax.legend(title=\"Topics\", bbox_to_anchor=(1.05, 1), loc='upper left')  # Place legend outside the plot\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMoo8VNBDSor"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named 'temp_df' and contains 'Source' and 'Topic' columns\n",
        "\n",
        "# Group data by source and topic, and count occurrences\n",
        "source_topic_counts = temp_df.groupby(['Source', 'Topic'])['Topic'].count().unstack()\n",
        "\n",
        "# Get source and topic labels\n",
        "sources = source_topic_counts.index\n",
        "topic_labels = [topic_titles[i] for i in range(lda.n_components)]  # Assuming you have topic_titles defined\n",
        "\n",
        "# Create the stacked bar chart\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot bars for each topic within each source\n",
        "bottom = [0] * len(sources)  # Initialize bottom for stacking\n",
        "for i, topic_label in enumerate(topic_labels):\n",
        "    ax.bar(sources, source_topic_counts[i], label=topic_label, bottom=bottom)\n",
        "    bottom = [bottom[j] + source_topic_counts[i][j] for j in range(len(sources))]\n",
        "\n",
        "# Set chart labels and formatting\n",
        "ax.set_xlabel(\"Source\")\n",
        "ax.set_ylabel(\"Number of Documents\")\n",
        "ax.set_title(\"Topic Distribution Across Sources\")\n",
        "ax.legend(title=\"Topics\", bbox_to_anchor=(1.05, 1), loc='upper left')  # Place legend outside the plot\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pcK2Z12Ek5e"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get feature names (words) from the vectorizer\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dictionary to store the word clouds for each topic\n",
        "topic_wordclouds = {}\n",
        "\n",
        "# Iterate through each topic\n",
        "for topic_index in range(lda.n_components):\n",
        "    # Get documents belonging to the current topic\n",
        "    topic_documents = temp_df[temp_df[\"Topic\"] == topic_index][\"Text\"]\n",
        "\n",
        "    # Create a frequency dictionary for words in the topic documents\n",
        "    word_frequencies = {}\n",
        "    for doc in topic_documents:\n",
        "        for word in tokenize_text(doc):  # Use your tokenize_text function\n",
        "            if word in feature_names:\n",
        "                word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
        "\n",
        "    # Create a WordCloud object\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(word_frequencies)\n",
        "\n",
        "    # Store the word cloud in the dictionary\n",
        "    topic_wordclouds[topic_index] = wordcloud\n",
        "\n",
        "    # Display the word cloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Word Cloud for Topic {topic_index}: {topic_titles[topic_index]}\")  # Assuming you have topic_titles\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpImPkudFx6c"
      },
      "source": [
        "## Test extract ADJ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvHuTTfPhRw5"
      },
      "source": [
        "Text is there now, we need to extract the dimensions for each of the companies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChDXGsyahRw7"
      },
      "outputs": [],
      "source": [
        "dimensions = [\"Effectiveness\", \"Innovation\", \"Ethics\", \"Empathy\", \"Aesthetic\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWh1P-cyhRw8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define your semantic dimensions with positive/negative poles\n",
        "dimensions = {\n",
        "    \"effectiveness\": (\"efficient\", \"inefficient\"),\n",
        "    \"innovation\": (\"innovative\", \"outdated\"),\n",
        "    \"trust\": (\"honest\", \"manipulative\"),\n",
        "    \"empathy\": (\"caring\", \"cold\"),\n",
        "    \"aesthetic\": (\"sleek\", \"ugly\")\n",
        "}\n",
        "\n",
        "# Pre-encode the pole vectors for speed\n",
        "anchor_vectors = {\n",
        "    dim: {\n",
        "        \"pos\": model.encode(pos, convert_to_tensor=True),\n",
        "        \"neg\": model.encode(neg, convert_to_tensor=True)\n",
        "    }\n",
        "    for dim, (pos, neg) in dimensions.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRjsX0naFQx1"
      },
      "outputs": [],
      "source": [
        "def score_adjective_on_dimensions(adj):\n",
        "    vec = model.encode(adj, convert_to_tensor=True)\n",
        "    scores = {}\n",
        "    for dim, anchors in anchor_vectors.items():\n",
        "        pos_sim = util.cos_sim(vec, anchors[\"pos\"])\n",
        "        neg_sim = util.cos_sim(vec, anchors[\"neg\"])\n",
        "        score = (pos_sim - neg_sim).item()\n",
        "        scores[dim] = score\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBaTgrNQFPrL"
      },
      "outputs": [],
      "source": [
        "def extract_adjectives(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc if token.pos_ == \"ADJ\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "AzWQDqywg1sE",
        "outputId": "2fb2f7e5-a3ea-42e3-83c1-64693db613c6"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-60a49ab05edd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0madjectives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_adjectives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0madj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjectives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mdim_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_adjective_on_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdim_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcompany_profiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7ad50c703bc6>\u001b[0m in \u001b[0;36mscore_adjective_on_dimensions\u001b[0;34m(adj)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_adjective_on_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchor_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"hpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mmodule_kwarg_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mmodule_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_kwarg_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m         }\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "company_profiles = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "# for company, posts in data.items():\n",
        "#     for post in posts:\n",
        "#         adjectives = extract_adjectives(post)\n",
        "#         for adj in adjectives:\n",
        "#             dim_scores = score_adjective_on_dimensions(adj)\n",
        "#             for dim, score in dim_scores.items():\n",
        "#                 company_profiles[company][dim].append(score)\n",
        "\n",
        "for company in preprocessed_text_data:\n",
        "  for text in preprocessed_text_data[company]:\n",
        "    adjectives = extract_adjectives(text)\n",
        "    for adj in adjectives:\n",
        "      dim_scores = score_adjective_on_dimensions(adj)\n",
        "      for dim, score in dim_scores.items():\n",
        "        company_profiles[company][dim].append(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx06O-VVljw2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "final_scores = {}\n",
        "for company, dims in company_profiles.items():\n",
        "    final_scores[company] = {\n",
        "        dim: round(np.mean(scores), 3)\n",
        "        for dim, scores in dims.items() if scores\n",
        "    }\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(final_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6MfcLW1GESE"
      },
      "outputs": [],
      "source": [
        "# # 5 random items from list\n",
        "# import random\n",
        "# sample = random.sample(preprocessed_text_data[\"Walmart\"], 10)\n",
        "\n",
        "# for samp in sample:\n",
        "#   print(\"============================ THE TEXT IS =============================\")\n",
        "#   print(samp)\n",
        "#   print(\"                            THE ADJECTIVES ARE                        \")\n",
        "#   print(extract_adjectives(samp))\n",
        "#   print(\"==================================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq9IbBZigbSa"
      },
      "outputs": [],
      "source": [
        "preprocessed_text_data[\"Walmart\"][2000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoG1Dl1Q5XEA"
      },
      "source": [
        "## Sentence based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my3gPggH59vg"
      },
      "outputs": [],
      "source": [
        "company_profiles_wholeText = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "for company in preprocessed_text_data:\n",
        "  for text in preprocessed_text_data[company]:\n",
        "    dim_scores = score_adjective_on_dimensions(text)\n",
        "    for dim, score in dim_scores.items():\n",
        "      company_profiles_wholeText[company][dim].append(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6tWSFIa7784"
      },
      "outputs": [],
      "source": [
        "# dimensions of a dictionary\n",
        "company_profiles_wholeText.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO0Kcu9V59vh"
      },
      "outputs": [],
      "source": [
        "\n",
        "final_scores_wholeText = {}\n",
        "for company, dims in company_profiles_wholeText.items():\n",
        "    final_scores_wholeText[company] = {\n",
        "        dim: round(np.mean(scores), 3)\n",
        "        for dim, scores in dims.items() if scores\n",
        "    }\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(final_scores_wholeText)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNXI4K/oNnVCL2iMsV+lF4j",
      "collapsed_sections": [
        "Q2hxQOwwMfMC",
        "5ERuRvey7k_S",
        "SpImPkudFx6c",
        "HoG1Dl1Q5XEA"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
